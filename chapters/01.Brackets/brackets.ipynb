{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Bracket search\n### Michiel Stock\n### 2019-2020"
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "using Plots\nusing STMO: myred, myblue, mygreen, myyellow, myorange,myblack"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "As a first introduction to mathematical optimization, we will study two *bracketing methods*. Bracketing methods can be used to minimize scalar function with a single input variable. These algorithms identify an interval $[a, b]$ containing the desired minimum. We will assume that the functions are *unimodal* they contain a single minimum.\n\n# Bisection method\n\nThe bisection method is technically not a minimization algorithm, but a *root finding method*, i.e., it can be used to find an $x$ for a given function $g: \\mathbb{R}\\rightarrow \\mathbb{R}$ such that\n\n$$\ng(x) = 0\\,.\n$$\n\nWe can use the bisection method to find a minimum of a function $f(x0$ by finding points where the first derivative $f'(x)$ is equal to 0.\n\n> **Question**: in addition to the first derivative being equal to zero, which other criterion should hold for $x^\\star$ to be a minimizer?\n\nThe bisection method departs from an inital bracket $[a, b]$, where $f(a)$ and $f(b)$ have opposing signs. If $f'(x)$ is a continious function, the *intermediate value theorem* states that there is at least one $x\\in[a,b]$ such that $f'(x)$.\n\nIn every step of the bisection method, the interval it cut into half. The midpoint $x = (b-a)/2$ is computed, and a new bracket is formed from the midpoint and the side that contains zero."
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "g(x) = tanh(sin(x))\n\na, b = -0.75, 1.2\n\nplot(g, -pi/2:0.1:pi/2, label=\"g(x)\", lw=2, color=myblue, xlabel=:x, legend=:left)\nscatter!([a], [g(a)], color=myorange, label=:a)\nscatter!([b], [g(b)], color=mygreen, label=:b)\nvline!([(b+a)/2], color=myred, label=\"midpoint\", lw=2)\nhline!([0], label=\"\", color=myblack, ls=:dash)\ntitle!(\"Illustration of the bisection method\")"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "The bisection procedure is repeated until the length of the interval is smaller than a small $\\epsilon > 0$. This $\\epsilon$ is called a *convergence parameter*, because it determines when the algorithm will halt. The pseudocode of the bisection method is given below.\n\n> **given** $f'(x)$, the derivative of a function, initial interval $[a, b]$, tollerance $\\epsilon$.\n>\n> **while** $b - a > \\epsilon$\n>> 1. *Determine midpoint*. $x:=(a+b)/2$\n>> 2. *Update*.\n>>> **if $f'(x)=0$**: $a:=x$, $b:=x$\n>>> **else if $\\text{sign}(f'(x)) = \\text{sign}(f'(a))$**: $a:=x$\n>>> **else**: $b:=x$\n>\n> **Output**: $[a, b]$\n\nSince every step shrinks the interval with a factor two, it is easy to show that this procedure stops within\n\n$$\n\\log_2(\\frac{b-a}{\\epsilon})\n$$\n\niterations.\n\n**Assignment 1** Complete the code for the bisection method. Use it to find the minimum of\n\n$$\nf(x) = \\log(e^{-x} + \\frac{x^2}{2})\n$$\n\nCheck your result graphically."
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "function bisection(f′, a, b; ϵ=1e-3)\n  @assert a < b, \"a should be smaller than b\"\n\n  # a is minizer?\n  f′(a) == 0 && return a, a\n  # b is minizer?\n  f′(b) == 0 && return b, b\n\n  while ...\n    ...\n  end\n  return a, b\nend"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "f(x) = log(exp(-x) + 0.5x^2)"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "f′(x) = ..."
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Quadratic fit search\n\nAs we will see in the next lecture, finding the minimum of quadratic functions of the form\n\n$$\nq(x) = p_1 + p_2 x + p_3 x^2\n$$\n\nis trivial. The *quadratic fit search method* will approximate a function by a quadratic function and computes the minimizer of that function.\n\nGiven three bracketing points $a<b<c$ and their resprective evaluations $y_a=f(a), y_b=f(b)$ and $y_c=f(c)$, we can fit a quadratic curve by solving the following system of equations for the coefficients:\n\n$$\n\\begin{bmatrix}y_a\\\\ y_b \\\\ y_c\\end{bmatrix} = \\begin{bmatrix}1 & a & a^2 \\\\ 1 & b & b^2 \\\\ 1 & c & c^2 \\end{bmatrix} \\begin{bmatrix}p_1\\\\ p_2 \\\\ p_3\\end{bmatrix}\\,.\n$$\n\nFor example, in Julia, we have:"
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "a, b, c = -2, -1, 5\nya, yb, yc = f.([a, b, c])\n\np1, p2, p3 = [1 a a^2; 1 b b^2; 1 c c^2] \\ [ya, yb, yc]"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can even dispense solving the system and use a closed-form fit based on three points:\n\n$$\nq(x) = y_a\\frac{(x-b)(x-c)}{(a-b)(a-c)} +  y_b\\frac{(x-a)(x-c)}{(b-a)(b-c)}+ y_c\\frac{(x-a)(x-b)}{(c-a)(c-b)}\\,.\n$$\n\nThe unique minimum of this quadratic curve is computed by:\n\n$$\nx^\\star = \\frac{1}{2} \\frac{y_a(b^2-c^2) + y_b(c^2-a^2)+ y_c(a^2-b^2)}{y_a(b-c) + y_b(c-a)+ y_c(a-b)}\\,.\n$$\n\nWe have implemented these two formulas in `quadratic_fit` and `quadratic_fit_min`. See below for an illustration."
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "function quadratic_fit(a, b, c, ya, yb, yc)\n  @assert a != b != c\n  return x -> ya * (x-b) * (x-c)/(a-b)/(a-c) +\n    yb * (x-a)*(x-c)/(b-a)/(b-c) +\n    yc * (x-a)*(x-b)/(c-a)/(c-b)\nend\n\nfunction quadratic_fit_min(a, b, c, ya, yb, yc)\n  return 0.5 * (ya*(b^2-c^2) + yb*(c^2-a^2) + yc*(a^2 + b^2)) \\\n        (ya*(b-c) + yb*(c-a) + yc*(a + b))\nend"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "x = quadratic_fit_min(a, b, c, ya, yb, yc)"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "plot(f, -5:0.1:7, label=\"f(x)\", lw=2, xlabel=:x, color=myblue)\nscatter!([a, b, c], [ya, yb, yc], label=\"a, b, c\", color=myorange)\nplot!(quadratic_fit(a, b, c, ya, yb, yc), -5:0.1:7, label=\"quadratic fit\", lw=2, color=mygreen)\nvline!([x], label=\"x\", lw=2, color=myred)"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "Given the minimizer $x^\\star$ of the quadratic approximation, we can update the interval closer to this value. The quadratic fit search repeats this approach $n$ times. The pseudocode is given below.\n\n> **given** $f(x)$, the function to be minimized, three increasing values $a, b, c$ with $f(a) > f(b)$ and $f(c) > f(b)$, the number of steps $n$.\n>\n> **repeat** $n$ times\n>> 1. *Fit quadratic*: and set $x$ as its minimizer\n>> 2. *Update bracket*:\n>>> **if $x\\in [a,b]$**: $a, b, c := a, x, b$\n>>> **else**: $a, b, c := b, x, c$\n>\n> **Output**: $a, b, c$\n\n**Assignment 2** Complete the code for the quadratic fit search method. Use it again to find the minimizer of the provided $f(x)$."
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "function quadratic_fit_search(f, a, b, c, n)\n  @assert a < b < c, \"a, b, c not consecutive \"\n  @assert f(a) > f(b) && f(c) > f(b), \"no local minimum between a and b\"\n\n  for i in 1:n\n    ...\n    ...\n  end\n  return a, b, c\nend"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "The coming chapters will discuss the minimization of quadratic function in much greater detail.\n\n# References\n\n- Kochenderfer, M. J. and Wheeler, T., '*Algorithms for Optimization*'. MIT Press (2019)"
      ],
      "metadata": {}
    }
  ],
  "nbformat_minor": 2,
  "metadata": {
    "language_info": {
      "file_extension": ".jl",
      "mimetype": "application/julia",
      "name": "julia",
      "version": "1.3.0"
    },
    "kernelspec": {
      "name": "julia-1.3",
      "display_name": "Julia 1.3.0",
      "language": "julia"
    }
  },
  "nbformat": 4
}
